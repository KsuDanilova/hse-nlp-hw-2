{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "Выберите корпус отзывов на товары одной из категорий Amazon:\n",
    "http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "\n",
    "Допустим, что вам нужно подготовить аналитический отчет по этим отзывам — например, для производителя нового продукта этой категории. Для этого будем искать упоминания товаров в отзывах (будем считать их NE). Учтите, что упоминание может выглядеть не только как \"Iphone 10\", но и как \"модель\", \"телефон\" и т.п.\n",
    "\n",
    "**Важное замечание**: в задании приводятся примеры решений, вы можете их использовать!\n",
    "\n",
    "\n",
    "### Варианты решения:\n",
    "\n",
    "1. **Rule-based** – пишем правила (синтаксические шаблоны) с помощью yargy.\n",
    "- Достоинства: скорость\n",
    "- Недостатки: достаточно сложно составлять правила (из много)\n",
    "   \n",
    "2. **Classification-based** - делаем бинарную классификацию (NER/неNER). \n",
    "   - Достоинства: скорость\n",
    "   - Недостатки: достаточно сложно составлять правила (из много)\n",
    "   \n",
    "3. **SpaCy** – готовая модель\n",
    "   - Достоинства: скорость, простота\n",
    "   - Недостатков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import string\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy; nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('Software_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12800</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>07 16, 2016</td>\n",
       "      <td>A1E50L7PCVXLN4</td>\n",
       "      <td>B01FFVDY9M</td>\n",
       "      <td>{'Platform:': ' Key Card'}</td>\n",
       "      <td>Colinda</td>\n",
       "      <td>When I ordered this it was listed as Photo Edi...</td>\n",
       "      <td>File Management Software with Basic Editing Ca...</td>\n",
       "      <td>1468627200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12801</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>06 17, 2017</td>\n",
       "      <td>AVU1ILDDYW301</td>\n",
       "      <td>B01HAP3NUG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G. Hearn</td>\n",
       "      <td>This software has SO much going on.  Theres a ...</td>\n",
       "      <td>Might not be for the \"novice\"</td>\n",
       "      <td>1497657600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12802</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>01 24, 2017</td>\n",
       "      <td>A2LW5AL0KQ9P1M</td>\n",
       "      <td>B01HAP3NUG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr. E</td>\n",
       "      <td>I have used both more complex and less complex...</td>\n",
       "      <td>Great, Inexpensive Software for Those Who Have...</td>\n",
       "      <td>1485216000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>06 14, 2018</td>\n",
       "      <td>AZ515FFZ7I2P7</td>\n",
       "      <td>B01HAP47PQ</td>\n",
       "      <td>{'Platform:': ' PC Disc'}</td>\n",
       "      <td>Jerry Jackson Jr.</td>\n",
       "      <td>Pinnacle Studio 20 Ultimate is a perfectly ser...</td>\n",
       "      <td>Gets the job done ... but not as easy as it sh...</td>\n",
       "      <td>1528934400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12804</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>04 16, 2018</td>\n",
       "      <td>A2WPL6Y08K6ZQH</td>\n",
       "      <td>B01HAP47PQ</td>\n",
       "      <td>{'Platform:': ' PC Disc'}</td>\n",
       "      <td>Narut Ujnat</td>\n",
       "      <td>A program that is fairly easy to use and provi...</td>\n",
       "      <td>Good overall program.</td>\n",
       "      <td>1523836800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified   reviewTime      reviewerID        asin  \\\n",
       "12800      4.0     False  07 16, 2016  A1E50L7PCVXLN4  B01FFVDY9M   \n",
       "12801      3.0     False  06 17, 2017   AVU1ILDDYW301  B01HAP3NUG   \n",
       "12802      4.0     False  01 24, 2017  A2LW5AL0KQ9P1M  B01HAP3NUG   \n",
       "12803      3.0     False  06 14, 2018   AZ515FFZ7I2P7  B01HAP47PQ   \n",
       "12804      4.0     False  04 16, 2018  A2WPL6Y08K6ZQH  B01HAP47PQ   \n",
       "\n",
       "                            style       reviewerName  \\\n",
       "12800  {'Platform:': ' Key Card'}            Colinda   \n",
       "12801                         NaN           G. Hearn   \n",
       "12802                         NaN              Dr. E   \n",
       "12803   {'Platform:': ' PC Disc'}  Jerry Jackson Jr.   \n",
       "12804   {'Platform:': ' PC Disc'}        Narut Ujnat   \n",
       "\n",
       "                                              reviewText  \\\n",
       "12800  When I ordered this it was listed as Photo Edi...   \n",
       "12801  This software has SO much going on.  Theres a ...   \n",
       "12802  I have used both more complex and less complex...   \n",
       "12803  Pinnacle Studio 20 Ultimate is a perfectly ser...   \n",
       "12804  A program that is fairly easy to use and provi...   \n",
       "\n",
       "                                                 summary  unixReviewTime vote  \\\n",
       "12800  File Management Software with Basic Editing Ca...      1468627200  NaN   \n",
       "12801                      Might not be for the \"novice\"      1497657600  NaN   \n",
       "12802  Great, Inexpensive Software for Those Who Have...      1485216000  NaN   \n",
       "12803  Gets the job done ... but not as easy as it sh...      1528934400  NaN   \n",
       "12804                              Good overall program.      1523836800  NaN   \n",
       "\n",
       "      image  \n",
       "12800   NaN  \n",
       "12801   NaN  \n",
       "12802   NaN  \n",
       "12803   NaN  \n",
       "12804   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['reviewText'], inplace=True)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['reviewText'].tolist()\n",
    "summaries = df['summary'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем частотные глаголы и существительные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619c0efdad7b49e0b6bce994fca9fcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('have', 19660),\n",
       " ('use', 16735),\n",
       " ('do', 9871),\n",
       " ('get', 7832),\n",
       " ('work', 6988),\n",
       " ('make', 5866),\n",
       " ('go', 5189),\n",
       " ('be', 5139),\n",
       " ('find', 5071),\n",
       " ('need', 5007)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = Counter()\n",
    "reviews_lemmas = []\n",
    "for review in tqdm(reviews):\n",
    "    doc = nlp(review)\n",
    "    review_lemmas = []\n",
    "    for token in doc:\n",
    "        review_lemmas.append(token.lemma_)\n",
    "        if token.pos_ == 'VERB':\n",
    "            verbs[token.lemma_] += 1\n",
    "    reviews_lemmas.append(' '.join(review_lemmas))\n",
    "    \n",
    "verbs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817bf4eb0d274a31b148b60ae58df41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('star', 1335),\n",
       " ('product', 565),\n",
       " ('software', 537),\n",
       " ('program', 309),\n",
       " ('version', 274),\n",
       " ('year', 239),\n",
       " ('price', 214),\n",
       " ('feature', 176),\n",
       " ('time', 172),\n",
       " ('computer', 167)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = Counter()\n",
    "summaries_lemmas = []\n",
    "for summary in tqdm(summaries):\n",
    "    if pd.isna(summary):\n",
    "        summaries_lemmas.append([])\n",
    "        continue\n",
    "    \n",
    "    doc = nlp(summary)\n",
    "    summary_lemmas = []\n",
    "    for token in doc:\n",
    "        summary_lemmas.append(token.lemma_) \n",
    "        if token.pos_ == 'NOUN':\n",
    "            nouns[token.lemma_] += 1\n",
    "    summaries_lemmas.append(' '.join(summary_lemmas))\n",
    "    \n",
    "nouns.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем правила с помощью Spacy matcher и ищем строки с упоминаниями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\n",
    "    \"verb_pattern\", \n",
    "    [\n",
    "        [\n",
    "            {\n",
    "                \"LEMMA\": {\n",
    "                    \"IN\": [\n",
    "                        \"use\", \n",
    "                        \"like\", \n",
    "                        \"instal\"\n",
    "                    ]\n",
    "                }\n",
    "            }, \n",
    "            {\n",
    "                \"lower\": \"this\", \n",
    "                \"OP\": \"*\"\n",
    "            }, \n",
    "            {\n",
    "                \"POS\": \"PROPN\", \n",
    "                \"OP\": \"+\"\n",
    "            }\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "matcher.add(\n",
    "    \"this_pattern\", \n",
    "    [\n",
    "        [\n",
    "            {\n",
    "                \"lower\": \"this\"\n",
    "            }, \n",
    "            {\n",
    "                \"POS\": {\n",
    "                    \"IN\": [\n",
    "                        \"PROPN\", \n",
    "                        \"NOUN\"\n",
    "                    ]\n",
    "                }, \n",
    "                \"OP\": \n",
    "                \"+\"\n",
    "            }, \n",
    "            {\n",
    "                \"LEMMA\": {\n",
    "                    \"IN\": [\n",
    "                        \"be\", \n",
    "                        \"have\"\n",
    "                    ]\n",
    "                }\n",
    "            }, \n",
    "            {\n",
    "                \"POS\": \"ADJ\", \n",
    "                \"OP\": \"*\"\n",
    "            }\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "matcher.add(\n",
    "    \"descriptor_pattern\", \n",
    "    [\n",
    "        [\n",
    "            {\n",
    "                \"POS\": \"PROPN\"\n",
    "            }, \n",
    "            {\n",
    "                \"POS\": \"PROPN\", \n",
    "                \"OP\": \"*\"\n",
    "            }, \n",
    "            {\n",
    "                \"lower\": {\n",
    "                    \"IN\": [\n",
    "                        \"program\", \n",
    "                        \"software\", \n",
    "                        \"player\", \n",
    "                        \"package\", \n",
    "                        \"tool\", \n",
    "                        \"game\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(text):\n",
    "    doc = nlp(text)\n",
    "    return filter_spans([doc[start:stop] for _, start, stop in matcher(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_products(match):\n",
    "    tokens = [token.text.lower() for token in match]\n",
    "    if tokens[0] in [\"use\", \"like\", \"instal\"]:\n",
    "        product = ' '.join(tokens[1:])\n",
    "    elif 'this' in tokens:\n",
    "        this_ind = tokens.index('this')\n",
    "        if 'be' in tokens:\n",
    "            verb_ind = tokens.index('be')\n",
    "        elif 'have' in tokens:\n",
    "            verb_ind = tokens.index('have')         \n",
    "        product = ' '.join(tokens[this_ind+1:verb_ind])\n",
    "    elif tokens[-1] in [\"program\", \"software\", \"player\", \"package\", \"tool\", \"game\"]:\n",
    "        product = ' '.join(tokens)    \n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_mentions(text):\n",
    "    all_prodnames = []\n",
    "    for span in get_spans(text):\n",
    "        try:\n",
    "            mention = extract_products(span)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        all_prodnames.append(mention)\n",
    "    return all_prodnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a91622f4a5f47de981e95a89cc76f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['dreamweaver',\n",
       " 'course',\n",
       " 'courseware',\n",
       " 'course',\n",
       " 'flash files',\n",
       " 'flash video',\n",
       " 'div',\n",
       " 'ap',\n",
       " 'spry',\n",
       " 'dw']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_mentions = [\n",
    "    get_products_mentions(text) for text in tqdm(reviews_lemmas)\n",
    "]\n",
    "products_mentions = sum(products_mentions, [])\n",
    "products_mentions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c60d0c92c8455299b73f9cd6e513d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('i', 'have'), 6616),\n",
       " (('it', \"'s\"), 5173),\n",
       " (('it', 'is'), 4617),\n",
       " (('i', \"'ve\"), 3276),\n",
       " (('i', \"'m\"), 3035),\n",
       " (('and', 'i'), 2997),\n",
       " (('that', 'i'), 2922),\n",
       " (('the', 'software'), 2917),\n",
       " (('i', 'was'), 2904),\n",
       " (('the', 'program'), 2673)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwe_tokenizer = MWETokenizer(separator=\" \")\n",
    "for products_mention in products_mentions:\n",
    "    mwe_tokenizer.add_mwe(tuple(products_mention.split()))\n",
    "    \n",
    "bigrams = Counter()\n",
    "reviews_lemmas_mwe = []\n",
    "for review in tqdm(reviews):\n",
    "    tokens = mwe_tokenizer.tokenize(word_tokenize(review.lower()))\n",
    "    reviews_lemmas_mwe.append(tokens)\n",
    "    \n",
    "    review_bigrams = list(nltk.bigrams(tokens))\n",
    "    review_bigrams_filtered = []\n",
    "    for review_bigram in review_bigrams:\n",
    "        if review_bigram[0] in string.punctuation or review_bigram[1] in string.punctuation:\n",
    "            continue\n",
    "        if review_bigram[0] in products_mentions or review_bigram[1] in products_mentions:\n",
    "            review_bigrams_filtered.append(review_bigram)\n",
    "    bigrams.update(review_bigrams_filtered)\n",
    "    \n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4b9513d19b451bbd8a805e3a228a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collocation_measures = nltk.collocations.BigramAssocMeasures()\n",
    "collocation_finder = BigramCollocationFinder.from_documents(reviews_lemmas_mwe)\n",
    "\n",
    "pmi = []\n",
    "likelihood_ratio = []\n",
    "student_t = []\n",
    "for bigram in tqdm(bigrams):\n",
    "    pmi.append(\n",
    "        (\n",
    "            bigram, \n",
    "             collocation_finder.score_ngram(\n",
    "                 collocation_measures.pmi, \n",
    "                 bigram[0], \n",
    "                 bigram[1]\n",
    "             )\n",
    "        )\n",
    "    )\n",
    "    likelihood_ratio.append(\n",
    "        (\n",
    "            bigram, \n",
    "            collocation_finder.score_ngram(\n",
    "                collocation_measures.likelihood_ratio, \n",
    "                bigram[0], \n",
    "                bigram[1]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    student_t.append(\n",
    "        (\n",
    "            bigram, \n",
    "            collocation_finder.score_ngram(\n",
    "                collocation_measures.student_t, \n",
    "                bigram[0], \n",
    "                bigram[1]\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сущеностей получилось много, поэтому сохраняю все в отдельный файл csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_group(bigram):\n",
    "    if bigram[0] in products_mentions:\n",
    "        return bigram[0]\n",
    "    elif bigram[1] in products_mentions:\n",
    "        return bigram[1]\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores['bigram'] = [b[0] for b in pmi]\n",
    "scores['pmi'] = [b[1] for b in pmi]\n",
    "scores['likelihood_ratio'] = [b[1] for b in likelihood_ratio]\n",
    "scores['student_t'] = [b[1] for b in student_t]\n",
    "scores['item_group'] = scores['bigram'].apply(get_item_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_group</th>\n",
       "      <th>bigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* program</td>\n",
       "      <td>(like, * program)</td>\n",
       "      <td>7.498710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* program</td>\n",
       "      <td>(* program, is)</td>\n",
       "      <td>5.179029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, rely)</td>\n",
       "      <td>12.876201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, cds)</td>\n",
       "      <td>12.415228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* software</td>\n",
       "      <td>(backup, * software)</td>\n",
       "      <td>9.561079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_group                bigram        pmi\n",
       "0   * program     (like, * program)   7.498710\n",
       "1   * program       (* program, is)   5.179029\n",
       "2  * software    (* software, rely)  12.876201\n",
       "3  * software     (* software, cds)  12.415228\n",
       "4  * software  (backup, * software)   9.561079"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_scores = (\n",
    "    scores[\n",
    "        [\n",
    "            'item_group', \n",
    "            'bigram', \n",
    "            'pmi'\n",
    "        ]\n",
    "    ]\n",
    "    .groupby('item_group')\n",
    "    .apply(\n",
    "        lambda x: x.sort_values('pmi', ascending=False)\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "pmi_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_group</th>\n",
       "      <th>bigram</th>\n",
       "      <th>likelihood_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* program</td>\n",
       "      <td>(like, * program)</td>\n",
       "      <td>9.014803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* program</td>\n",
       "      <td>(* program, is)</td>\n",
       "      <td>5.821187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, will)</td>\n",
       "      <td>17.901573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, rely)</td>\n",
       "      <td>16.136121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, cds)</td>\n",
       "      <td>15.493911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_group              bigram  likelihood_ratio\n",
       "0   * program   (like, * program)          9.014803\n",
       "1   * program     (* program, is)          5.821187\n",
       "2  * software  (* software, will)         17.901573\n",
       "3  * software  (* software, rely)         16.136121\n",
       "4  * software   (* software, cds)         15.493911"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ratio_scores = (\n",
    "    scores[\n",
    "        [\n",
    "            'item_group', \n",
    "            'bigram', \n",
    "            'likelihood_ratio'\n",
    "        ]\n",
    "    ]\n",
    "    .groupby('item_group')\n",
    "    .apply(\n",
    "        lambda x: x.sort_values('likelihood_ratio', ascending=False)\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "likelihood_ratio_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_group</th>\n",
       "      <th>bigram</th>\n",
       "      <th>student_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>* program</td>\n",
       "      <td>(like, * program)</td>\n",
       "      <td>0.994471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* program</td>\n",
       "      <td>(* program, is)</td>\n",
       "      <td>0.972397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, will)</td>\n",
       "      <td>1.406138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, rely)</td>\n",
       "      <td>0.999867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* software</td>\n",
       "      <td>(* software, cds)</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_group              bigram  student_t\n",
       "0   * program   (like, * program)   0.994471\n",
       "1   * program     (* program, is)   0.972397\n",
       "2  * software  (* software, will)   1.406138\n",
       "3  * software  (* software, rely)   0.999867\n",
       "4  * software   (* software, cds)   0.999817"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_t_scores = (\n",
    "    scores[\n",
    "        [\n",
    "            'item_group', \n",
    "            'bigram', \n",
    "            'student_t'\n",
    "        ]\n",
    "    ]\n",
    "    .groupby('item_group')\n",
    "    .apply(\n",
    "        lambda x: x.sort_values('student_t', ascending=False)\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "student_t_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_scores.to_csv('pmi.csv')\n",
    "likelihood_ratio_scores.to_csv('likelihood_ratio.csv')\n",
    "student_t_scores.to_csv('student_t.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
